{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN.ipynb","provenance":[],"authorship_tag":"ABX9TyNOiK5ES8a1EYbHmTRbajbX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"JF2HTX2B2yhq"},"source":["import numpy as np\n","import pandas as pd\n","\n","def sigmoid(x):\n","  return 1/(1+np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","  return x*(1-x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bBagVwdTHX_Q"},"source":["class NeuralNetwork:\n","  def __init__(self, layers, alpha=0.1):\n","    self.layers = layers\n","    self.alpha = alpha\n","    self.W = []\n","    self.b = []\n","  # random initialize each parameter\n","    for i in range(0, len(layers)-1):\n","      w_ = np.random.randn(layers[i], layers[i+1])\n","      b_ = np.zeros((layers[i+1], 1))\n","      self.W.append(w_/layers[i])\n","      self.b.append(b_)\n","\n","  def __repr__(self):\n","    return \"Neural network [{}]\".format(\"-\".join(str(l) for l in self.layers))\n","  \n","  # Train\n","  def fit_partial(self, x, y):\n","    A = [x]\n","  # feedforward\n","    out = A[-1]\n","    for i in range(0, len(self.layers) - 1):\n","      out = sigmoid(np.dot(out, self.W[i]) + (self.b[i].T))\n","      A.append(out)\n","  # backpropagation\n","    y = y.reshape(-1, 1)\n","    dA = [-(y/A[-1] - (1-y)/(1-A[-1]))]\n","    dW = [] \n","    db = []\n","    for i in reversed(range(0, len(self.layers)-1)):\n","      dw_ = np.dot((A[i]).T, dA[-1] * sigmoid_derivative(A[i+1]))\n","      db_ = (np.sum(dA[-1] * sigmoid_derivative(A[i+1]), 0)).reshape(-1,1)\n","      dA_ = np.dot(dA[-1] * sigmoid_derivative(A[i+1]), self.W[i].T)\n","      dW.append(dw_)\n","      db.append(db_)\n","      dA.append(dA_)\n","\n","    dW = dW[::-1]\n","    db = db[::-1]\n","  # Gradient descent\n","    for i in range(0, len(self.layers)-1):\n","      self.W[i] = self.W[i] - self.alpha * dW[i]\n","      self.b[i] = self.b[i] - self.alpha * db[i]\n","  \n","  def fit(self, X, y, epochs=20, verbose=10):\n","    for epoch in range(0, epochs):\n","      self.fit_partial(X, y)\n","      if epoch % verbose == 0:\n","        loss = self.calculate_loss(X, y)\n","        print(\"Epoch {}, loss {}\".format(epoch, loss))\n","\n","  def predict(self, X):\n","    for i in range(0, len(self.layers) - 1):\n","      X = sigmoid(np.dot(X, self.W[i]) + (self.b[i].T))\n","      return X\n","\n","  def calculate_loss(self, X, y):\n","    y_predict = self.predict(X)\n","    #return np.sum((y_predict-y)**2)/2\n","    return -(np.sum(y*np.log(y_predict) + (1-y)*np.log(1-y_predict)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DgmlTfApObdv"},"source":[" W =[]\n"," b = []\n"," for i in range(0, 2-1):\n","      w_ = np.random.randn(layers[i], layers[i+1])\n","      b_ = np.zeros((layers[i+1], 1))\n","      W.append(w_/layers[i])\n","      b.append(b_)"],"execution_count":null,"outputs":[]}]}